plot.subtitle = element_text(colour = "white",size = 14,family = "arial"),
plot.caption = element_text(colour = "white",size = 10,family = "arial"),
# Legend
legend.position = "right",
legend.text = element_text(colour = "white",size = 12,family = "arial"),
legend.title = element_text(colour = "white",size = 12,family = "arial",hjust = 3,face = "bold"),
legend.key = element_rect(fill = "#000123", color = "#000123"),
legend.background = element_rect(fill = "#000123"),
# Other
axis.ticks = element_blank(),
strip.text = element_text(colour = "white",size = 12,family = "arial",vjust = 1,hjust = 0.5)
)
# Import data
path <- "/Users/janhendrikpretorius/Library/CloudStorage/OneDrive-StellenboschUniversity/Masters-2023/Modules/Data Science/DataScience-871-repo/JHPretorius-Project/Candidate Data Sets/Dating/"
file <- "lovoo_v3_users_api-results.csv"
df <- read_csv(paste0(path, file))
knitr::include_graphics("lovoo_logo.png")
head(df)
# Define stop words for different languages
all_stop_words <- c(stopwords::stopwords("de"), stopwords::stopwords("en"), stopwords::stopwords("fr"))
# Define dummy variable that detects presence of emojis
# Also remove digits from 'whazzup' column
df <- df %>%
mutate(has_emoji = ifelse(emoji_detect(whazzup), 1, 0),
whazzup = str_remove_all(whazzup, "[[:digit:]]+"))
# Get the most used words in profile
# First, create a table of words with the corresponding counts_profileVisits
words_visits <- df %>%
unnest_tokens(word, whazzup) %>%
select(word, counts_profileVisits)
# Then calculate the mean counts_profileVisits for each word and its count
words <- words_visits %>%
group_by(word) %>%
summarise(mean_profileVisits = mean(counts_profileVisits, na.rm = TRUE),
word_count = n(),
.groups = "drop")
# Create word popularity index and determine popular words
words <- words %>%
mutate(popularity_index = 0.8 * word_count + 0.2 * mean_profileVisits) %>%
filter(popularity_index > 200 & word_count > 10,
word != "",
!is.na(word),
!is.na(mean_profileVisits),
!is.na(word_count),
!is.na(popularity_index)) %>%
filter(!word %in% all_stop_words)
# Create a single pattern string that matches any word in words$word
words_pattern <- paste(words$word, collapse = "|")
# Add the new variable to df
df <- df %>%
mutate(contains_popular_word = ifelse(str_detect(whazzup, words_pattern), 1, 0)) %>%
mutate(
contains_popular_word = replace_na(contains_popular_word, 0),
has_emoji = replace_na(has_emoji, 0)
)
words <- words %>%
arrange(desc(popularity_index)) %>%
select(c(word, popularity_index))
# Create Word Cloud
wordcloud2(words, size=1.6, color='random-light', backgroundColor = "#000123")
social <- "instagram|insta|facebook|fb|snapchat|snap"
df <- df %>%
mutate(whazzup = tolower(whazzup),
has_social = as.numeric(str_detect(whazzup, social))) %>%
replace_na(list(has_social = 0))
df <- df %>%
mutate(night_owl = ifelse(hour(hms(substr(lastOnlineDate, 12, 19))) > 18 |
hour(hms(substr(lastOnlineDate, 12, 19))) < 6, 1, 0))
# Categorize counts_profileVisits and counts_kisses based on quartiles
df$Profile_Views <- cut(df$counts_profileVisits,
breaks = quantile(df$counts_profileVisits, probs = 0:4/4, na.rm = TRUE),
labels = c("Low", "Low Mid", "High Mid", "High"), include.lowest = TRUE)
df$Profile_Likes <- cut(df$counts_kisses,
breaks = quantile(df$counts_kisses, probs = 0:4/4, na.rm = TRUE),
labels = c("Low", "Low Mid", "High Mid", "High"), include.lowest = TRUE)
df$counts_profileVisitsStd <- scale(df$counts_profileVisits)
df$counts_kissesStd <- scale(df$counts_kisses)
df$counts_picturesStd <- scale(df$counts_pictures)
df %>%
filter(counts_profileVisits < 100000) %>%
ggplot(aes(x = counts_profileVisits, y = counts_kisses)) +
geom_point(aes(fill = factor(has_emoji), size = counts_details), pch = 21, alpha = 0.8, colour = "white") +
scale_fill_manual(values = c("#1beaa7", "#8c2aef"), name = "Has Emoji", labels = c("No Emoji", "Contains Emoji")) +
scale_size(range = c(0.1, 4)) +
labs(x = "Profile Visits Count", y = "Number of Kisses", size = "Details Count", fill = "Contains Emoji") +
th +
geom_smooth(aes(colour = factor(has_emoji)), method = "loess", se = FALSE) +
scale_colour_manual(values = c("#1beaa7", "#8c2aef"), name = "Has Emoji", labels = c("No Emoji", "Contains Emoji"))
plot1 <- df %>%
filter(counts_kissesStd < 2, !is.na(night_owl), !is.na(has_social)) %>%
mutate(has_emoji = factor(has_emoji, labels = c("No", "Yes")),
night_owl = factor(night_owl, labels = c("No", "Yes")),
has_social = factor(has_social, labels = c("No", "Yes"))) %>%
pivot_longer(cols = c(has_emoji, has_social), names_to = "Factor", values_to = "Value") %>%
mutate(Factor = recode(Factor,
has_emoji = "Emoji",
has_social = "Social Media")) %>%
ggplot(aes(x = Value, y = counts_kissesStd, fill = Value)) +
geom_boxplot(colour = "white", alpha = 0.8) +
scale_fill_manual(values = c("#1beaa7", "#8c2aef")) +
facet_wrap(~ Factor, scales = "free", strip.position = "top") +
labs(x = "", y = "Profile Kisses Count (Standardised)", fill = "") +
th +
theme(
strip.background = element_blank(),
strip.text = element_text(face = "bold", size = 14),
axis.text.x = element_blank(),
legend.position = "none"
) +
scale_y_continuous(breaks = c(-1, 0, 1, 2))
plot2 <- df %>%
filter(counts_profileVisitsStd < 2, !is.na(night_owl), !is.na(isOnline)) %>%
mutate(night_owl = factor(night_owl, labels = c("No", "Yes")),
isOnline = factor(isOnline, labels = c("No", "Yes"))) %>%
pivot_longer(cols = c(night_owl, isOnline), names_to = "Factor", values_to = "Value") %>%
mutate(Factor = recode(Factor,
night_owl = "Night Owl",
isOnline = "Online")) %>%
ggplot(aes(x = Value, y = counts_profileVisitsStd, fill = Value)) +
geom_boxplot(colour = "white", alpha = 0.8) +
scale_fill_manual(values = c("#1beaa7", "#8c2aef")) +
facet_wrap(~ Factor, scales = "free", strip.position = "top") +
labs(x = "", y = "Profile Visits Count (Standardised)", fill = "") +
th +
theme(
strip.background = element_blank(),
strip.text = element_text(face = "bold", size = 14),
axis.text.x = element_blank()
) +
scale_y_continuous(breaks = c(-1, 0, 1, 2))
plot1
plot2
# Note: commented out, due to costs associated with geocoding through the API
# df_city <- df %>%
#   select(c(city, country, counts_profileVisits)) %>%
#   mutate(address = paste0(city, ", ", country)) %>%
#   group_by(address) %>%
#   summarise(mean_profile_views = mean(counts_profileVisits, na.rm = TRUE))
#
# df_city <- df_city %>%
#   mutate(geocode_data = map(address, ~geocode(.x, source = "google", output = "latlon")),
#          lon = map_dbl(geocode_data, "lon"),
#          lat = map_dbl(geocode_data, "lat"))
#
# write_csv(df_city, "geocode_latlon.csv")
df_city <- read_excel("geocode_latlon.xlsx")
df_city <- df_city %>%
mutate(mean_profile_views = as.numeric(mean_profile_views),
lat = as.numeric(lat),
lon = as.numeric(lon)) %>%
filter(!is.na(lon),
mean_profile_views > 0,
lon > -90 & lon < 100,
lat > 0)
# Filter by countries after data cleaning and transformation
df_city <- df_city %>%
filter(substr(address, nchar(address) - 1, nchar(address)) %in% eu_countries$code | address == "UK"| address == "CZ" | address == "CH")
world <- map_data("world") %>%
filter(region %in% eu_countries$name | region == "UK" | region == "Czech Republic" | region == "Switzerland")
# Creating ggplot with map
map_bg <- ggplot(data = world) +
geom_polygon(aes(x = long, y = lat, group = group), fill = "white", colour = "#000123") +
coord_map() +
theme_void()
# Adding scatterplot on the map
views <- map_bg +
geom_point(data = df_city, aes(x = lon, y = lat, color = mean_profile_views, size = mean_profile_views), alpha = 0.8) +
scale_colour_gradient(
name = 'Mean Profile Views',
limits = range(df_city$mean_profile_views),
low = "#8c2aef",
high = "#1beaa7"
) +
scale_size_continuous(guide = "none", range = c(1, 8)) +
theme(plot.background = element_rect(fill = "#000123", color = "#000123"),
panel.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.text = element_blank(),
legend.key = element_rect(fill = "#000123", color = "#000123"),
legend.background = element_rect(fill = "#000123"),
legend.text = element_text(colour = "white"),
legend.title = element_text(colour = "white", face = "bold"))
print(views)
# Group by country and calculate mean profile views
df_city_grouped <- df_city %>%
mutate(country_code = substr(address, nchar(address) - 1, nchar(address))) %>%
group_by(country_code) %>%
summarise(mean_profile_views = mean(mean_profile_views, na.rm = TRUE))
# Convert two-letter country codes to full country names
df_city_grouped <- left_join(df_city_grouped, eu_countries, by = c("country_code" = "code"))
# Join with the 'world' dataframe
world <- left_join(world, df_city_grouped, by = c("region" = "name"))
world <- world %>%
filter(!is.na(mean_profile_views))
# Create the choropleth map
choropleth <- map_bg +
geom_polygon(data = world, aes(x = long, y = lat, fill = mean_profile_views, group = group), color = "#000123") +
scale_fill_gradient(name = 'Mean Profile Views',
low = "#8c2aef",
high = "#1beaa7",
na.value = "") +
theme(plot.background = element_rect(fill = "#000123", color = "#000123"),
legend.key = element_rect(fill = "#000123", color = "#000123"),
legend.background = element_rect(fill = "#000123"),
legend.text = element_text(colour = "white"),
legend.title = element_text(colour = "white", face = "bold"))
print(choropleth)
# Count the number of users per country in the 'df' dataframe
df_country_users <- df %>%
group_by(country) %>%
summarise(num_users = n())
# Convert two-letter country codes to full country names in df_country_users
df_country_users <- left_join(df_country_users, eu_countries, by = c("country" = "code"))
# Summarise mean_profile_views per country in df_city dataframe
df_city_grouped <- df_city %>%
mutate(country_code = substr(address, nchar(address) - 1, nchar(address))) %>%
group_by(country_code) %>%
summarise(mean_profile_views = mean(mean_profile_views, na.rm = TRUE))
# Join df_city_grouped with df_country_users to add the number of users per country
df_city_grouped <- left_join(df_city_grouped, df_country_users, by = c("country_code" = "country"))
# Create the lollipop chart with number of users and colored by mean profile views
ggplot(df_city_grouped, aes(x = reorder(name, -num_users), y = num_users)) +
geom_segment(aes(xend = name, yend = 0), color = "white") +
geom_point(aes(color = mean_profile_views), size = 3, alpha = 0.8) +
coord_flip() +
scale_color_gradient(name = 'Mean Profile Views', low = "#8c2aef", high = "#1beaa7") +
xlab("") +
ylab("Number of Users") + th +
theme(legend.position = "right",
panel.grid.major = element_blank(),
panel.grid.minor = element_blank())
# Calculate the correlation matrix
correlation_matrix <- cor(df[c("counts_kissesStd", "age", "lang_count", "flirtInterests_chat", "flirtInterests_friends",
"flirtInterests_date", "isMobile", "verified", "shareProfileEnabled")])
# Melt the correlation matrix
correlation_matrix_melt <- melt(correlation_matrix)
# Create the ggplot object
ggplot(data = correlation_matrix_melt, aes(x=Var1, y=Var2, fill=value)) +
geom_tile(color = "white") +
geom_text(aes(Var1, Var2, label = round(value, 2)), color = "black", size = 4) +
scale_fill_gradient2(low = "#8c2aef", high = "#1beaa7", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name="Correlation") +
th +
theme(
strip.background = element_blank(),
strip.text = element_text(face = "bold", size = 14),
axis.text.x = element_text(angle = 90, vjust = 1,
size = 12, hjust = 1),
axis.text.y = element_text(size = 12),
axis.title.x = element_blank(),
axis.title.y = element_blank(),
legend.position = "right") +
coord_fixed()
df_long <- df %>%
pivot_longer(cols = starts_with("lang_"),
names_to = "language",
values_to = "spoken") %>%
filter(spoken == TRUE) %>%
mutate(language = str_remove(language, "lang_"),
language = recode(language,
"de" = "German",
"en" = "English",
"es" = "Spanish",
"fr" = "French",
"it" = "Italian",
"pt" = "Portuguese"))
df_long %>%
filter(language != "count", counts_kisses < 1000) %>%
ggplot(aes(x = counts_kisses, y = language, fill = language)) +
geom_density_ridges(scale = 3, rel_min_height = 0.01, colour = "white", alpha = 0.8) +
scale_fill_manual(values = palette) +
geom_vline(aes(xintercept = 157.0227), linetype = "dashed", colour = "white") +
theme_ridges() +
th +
theme(legend.position = "none") +
labs(x = "Profile Kisses Count", y = "Language") +
annotate("text", x = 170, y = Inf, label = "Mean Kisses Received (~160)", vjust = 2, hjust = 0, size = 4, colour = "white")
df_summary <- df %>%
group_by(counts_pictures, has_social) %>%
summarise(mean_kisses = mean(counts_kisses, na.rm = TRUE),
.groups = "drop")
df_summary %>%
filter(counts_pictures < 19 & counts_pictures > 0) %>%
ggplot(aes(x = as.factor(counts_pictures), y = mean_kisses, colour = factor(has_social), group = (has_social))) +
geom_line(size = 1) +
geom_point() +
scale_colour_manual(values = c("#1beaa7", "#8c2aef"),
name = "Has Social Media",
labels = c("No Social", "Contains Social")) +
labs(x = "Pictures Count",
y = "Mean Profile Kisses Count",
colour = "Contains Social Media") +
th +
theme(legend.position = "right")
# Set seed for reproducibility
set.seed(777)
# Define training and testing sets for profile visits prediction
split_visits <- initial_split(df, prop = 0.7, strata = "Profile_Views")
training_visits <- training(split_visits)
testing_visits <- testing(split_visits)
# Set seed for reproducibility
set.seed(777)
# Define training and testing sets for likes prediction
split_kisses <- initial_split(df, prop = 0.7, strata = "Profile_Likes")
training_kisses <- training(split_kisses)
testing_kisses <- testing(split_kisses)
# Train decision tree model for profile visits
visits_tree <- rpart(formula = Profile_Views ~ isOnline + night_owl + age,
data = training_visits, method = "class")
summary(visits_tree)
# Train decision tree model for profile likes
kisses_tree <- rpart(formula = Profile_Likes ~ has_emoji + has_social + Profile_Views + counts_pictures + lang_count + flirtInterests_chat + flirtInterests_date + flirtInterests_friends + counts_details,
data = training_kisses, method = "class")
summary(kisses_tree)
# Predict on testing data
predict_visits <- predict(visits_tree, newdata = testing_visits, type = "class")
predict_kisses <- predict(kisses_tree, newdata = testing_kisses, type = "class")
# Confusion matrices for evaluation
confusionMatrix(predict_visits, testing_visits$Profile_Views)
confusionMatrix(predict_kisses, testing_kisses$Profile_Likes)
# Visualize the decision trees
rpart.plot(visits_tree, extra = 1)
rpart.plot(kisses_tree, extra = 1)
# Set seed for reproducibility
set.seed(777)
# Filter out NA values
training_visits <- training_visits %>% filter(!is.na(night_owl))
# Random Forest model for profile visits
visits_rf <- randomForest(formula = Profile_Views ~ isOnline + night_owl + age + genderLooking,
data = training_visits,
importance = TRUE,
ntree = 500)
# View model summary
visits_rf
# Random Forest model for profile likes
kisses_rf <- randomForest(formula = Profile_Likes ~ has_emoji + has_social + Profile_Views + counts_pictures + lang_count + flirtInterests_chat + flirtInterests_date + flirtInterests_friends + counts_details,
data = training_kisses,
importance = TRUE,
ntree = 500)
# View model summary
kisses_rf
# Predict on test data
visits_rf_pred <- predict(visits_rf, newdata = testing_visits)
kisses_rf_pred <- predict(kisses_rf, newdata = testing_kisses)
# Confusion matrices
confusionMatrix(visits_rf_pred, testing_visits$Profile_Views)
confusionMatrix(kisses_rf_pred, testing_kisses$Profile_Likes)
# Extract variable importance data
varImpData <- importance(kisses_rf, type = 1)
# Convert to data frame
varImpDF <- data.frame(
Importance = varImpData,
Variable = rownames(varImpData)
)
# Create plot
varImpPlot1 <- ggplot(varImpDF, aes(x = reorder(Variable, -MeanDecreaseAccuracy), y = MeanDecreaseAccuracy)) +
geom_segment(aes(xend = Variable, yend = 0), color = "white") + # Add lollipop 'sticks'
geom_point(stat = "identity", color = "#1beaa7", size = 3, alpha = 0.7) + # Add lollipop 'heads'
coord_flip() + # Flip axes
th + # Add your theme
labs(title = "Mean Decreases - Accuracy", x = "Variables", y = "Importance")
# Extract variable importance data
varImpData <- importance(kisses_rf, type = 2) # change type to 2 for MeanDecreaseGini
# Convert to data frame
varImpDF <- data.frame(
Importance = varImpData,
Variable = rownames(varImpData)
)
# Create plot
varImpPlot2 <- ggplot(varImpDF, aes(x = reorder(Variable, -MeanDecreaseGini), y = MeanDecreaseGini)) +
geom_segment(aes(xend = Variable, yend = 0), color = "white") +
geom_point(color = "#8c2aef", size = 3, alpha = 0.7) +
coord_flip() + # Flip axes
th +
labs(title = "Mean Decreases - Gini", x = "Variables", y = "Importance")
varImpPlot1
varImpPlot2
knitr::include_graphics("jan_logo.png")
knitr::include_graphics("jan_logo.png")
library(readxl)
econ_grades <- read_excel("~/Downloads/econ_grades.xlsx")
View(econ_grades)
library(readxl)
jan_classes <- read_excel("~/Downloads/jan_classes.xlsx")
View(jan_classes)
econ_grades$`Course total (Real)` <- as.numeric(econ_grades$`Course total (Real)`)
# Filter the econ_grades dataframe to include only rows where Username exists in jan_classes$Name
filtered_grades <- econ_grades %>% filter(Username %in% jan_classes$Name)
# Group the filtered data by Username and then calculate the average Course total (Real) for each group
averages <- filtered_grades %>%
group_by(Username) %>%
summarise(Average = mean(`Course total (Real)`, na.rm = TRUE))  # Assuming you want to ignore NA values
# Print the averages
print(averages)
View(filtered_grades)
mean(filtered_grades$`Course total (Real)`)
mean(econ_grades$`Course total (Real)`)
econ_grades <- econ_grades %>%
filter(!is.na(`Course total (Real)``))
mean(econ_grades$`Course total (Real)`)
mean(econ_grades$`Course total (Real)`)
econ_grades <- econ_grades %>%
filter(!is.na(`Course total (Real)``))
mean(econ_grades$`Course total (Real)`)
econ_grades <- econ_grades %>%
filter(!is.na(`Course total (Real)``))
# Load packages in use
pacman::p_load(dplyr, ggplot2, tidyverse, rsample, caret, glmnet, vip, pdp, stringr,
tidytext, emoji, stopwords, ggridges, wordcloud2, ggmap, readxl, maps,
viridis, eurostat, corrplot, GGally, reshape2, grid, rpart, rpart.plot,
randomForest)
econ_grades <- econ_grades %>%
filter(!is.na(`Course total (Real)``))
econ_grades <- econ_grades %>%
filter(!is.na(`Course total (Real)`))
mean(econ_grades$`Course total (Real)`)
mean(filtered_grades$`Course total (Real)`)
knitr::opts_chunk$set(echo = TRUE)
# Define stop words for different languages
all_stop_words <- c(stopwords::stopwords("de"), stopwords::stopwords("en"), stopwords::stopwords("fr"))
# Define dummy variable that detects presence of emojis
# Also remove digits from 'whazzup' column
df <- df %>%
mutate(has_emoji = ifelse(emoji_detect(whazzup), 1, 0),
whazzup = str_remove_all(whazzup, "[[:digit:]]+"))
# Clear environment
rm(list = ls())
options(scipen = 999)
# Load packages in use
pacman::p_load(dplyr, ggplot2, tidyverse, rsample, caret, glmnet, vip, pdp, stringr,
tidytext, emoji, stopwords, ggridges, wordcloud2, ggmap, readxl, maps,
viridis, eurostat, corrplot, GGally, reshape2, grid, rpart, rpart.plot,
randomForest)
# Define plot themes and palettes
palette <- c("#1beaa7", "#00d9d3", "#00c2ff", "#00a5ff", "#007bff", "#8c2aef")
th <- theme(
# Background and grid
panel.background = element_blank(),
plot.background = element_rect(fill = "#000123", color = "#000123"),
panel.grid.major = element_line(color = "white", size = 0.1),
panel.grid.minor = element_line(color = "white", size = 0.1),
# Axis titles and labels
axis.title.x = element_text(colour = "white",size = 12,family = "arial",vjust = -2,hjust = 0.5,face = "bold"),
axis.title.y = element_text(colour = "white",size = 12,family = "arial",vjust = 3,hjust = 0.5,face = "bold"),
axis.text.y = element_text(colour = "white",size = 10,family = "arial"),
axis.text.x = element_text(colour = "white",size = 10,family = "arial"),
# Margins and spacing
plot.margin = unit(c(0.5, 0.5, 0.5, 0.5), "cm"),
# Title, subtitle, and caption
plot.title = element_text(colour = "white",size = 16,family = "arial",hjust = 0.5,face = "bold"),
plot.subtitle = element_text(colour = "white",size = 14,family = "arial"),
plot.caption = element_text(colour = "white",size = 10,family = "arial"),
# Legend
legend.position = "right",
legend.text = element_text(colour = "white",size = 12,family = "arial"),
legend.title = element_text(colour = "white",size = 12,family = "arial",hjust = 3,face = "bold"),
legend.key = element_rect(fill = "#000123", color = "#000123"),
legend.background = element_rect(fill = "#000123"),
# Other
axis.ticks = element_blank(),
strip.text = element_text(colour = "white",size = 12,family = "arial",vjust = 1,hjust = 0.5)
)
# Import data
path <- "/Users/janhendrikpretorius/Library/CloudStorage/OneDrive-StellenboschUniversity/Masters-2023/Modules/Data Science/DataScience-871-repo/JHPretorius-Project/Candidate Data Sets/Dating/"
file <- "lovoo_v3_users_api-results.csv"
df <- read_csv(paste0(path, file))
head(df)
# Define stop words for different languages
all_stop_words <- c(stopwords::stopwords("de"), stopwords::stopwords("en"), stopwords::stopwords("fr"))
# Define dummy variable that detects presence of emojis
# Also remove digits from 'whazzup' column
df <- df %>%
mutate(has_emoji = ifelse(emoji_detect(whazzup), 1, 0),
whazzup = str_remove_all(whazzup, "[[:digit:]]+"))
# Get the most used words in profile
# First, create a table of words with the corresponding counts_profileVisits
words_visits <- df %>%
unnest_tokens(word, whazzup) %>%
select(word, counts_profileVisits)
# Then calculate the mean counts_profileVisits for each word and its count
words <- words_visits %>%
group_by(word) %>%
summarise(mean_profileVisits = mean(counts_profileVisits, na.rm = TRUE),
word_count = n(),
.groups = "drop")
# Create word popularity index and determine popular words
words <- words %>%
mutate(popularity_index = 0.8 * word_count + 0.2 * mean_profileVisits) %>%
filter(popularity_index > 200 & word_count > 10,
word != "",
!is.na(word),
!is.na(mean_profileVisits),
!is.na(word_count),
!is.na(popularity_index)) %>%
filter(!word %in% all_stop_words)
# Create a single pattern string that matches any word in words$word
words_pattern <- paste(words$word, collapse = "|")
# Add the new variable to df
df <- df %>%
mutate(contains_popular_word = ifelse(str_detect(whazzup, words_pattern), 1, 0)) %>%
mutate(
contains_popular_word = replace_na(contains_popular_word, 0),
has_emoji = replace_na(has_emoji, 0)
)
words <- words %>%
arrange(desc(popularity_index)) %>%
select(c(word, popularity_index))
View(words)
# Create Word Cloud
wordcloud2(words, size=1.6, color='random-light', backgroundColor = "#000123")
