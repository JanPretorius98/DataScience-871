df$counts_picturesStd <- scale(df$counts_pictures)
# Calculate the correlation matrix
correlation_matrix <- cor(df[c("counts_kisses", "counts_profileVisits", "counts_g", "verified", "counts_fans", "has_emoji", "has_social", "lang_count", "isMobile", "flirtInterests_chat", "flirtInterests_date", "isVip", "isHighlighted", "flirtInterests_friends", "shareProfileEnabled", "age")])
# Melt the correlation matrix
correlation_matrix_melt <- melt(correlation_matrix)
# Create the ggplot object
ggplot(data = correlation_matrix_melt, aes(x=Var1, y=Var2, fill=value)) +
geom_tile(color = "white") +
geom_text(aes(Var1, Var2, label = round(value, 2)), color = "black", size = 4) +
scale_fill_gradient2(low = "#8c2aef", high = "#1beaa7", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name="Correlation") +
th +
theme(
strip.background = element_blank(),
strip.text = element_text(face = "bold", size = 14),
axis.text.x = element_text(angle = 90, vjust = 1,
size = 12, hjust = 1),
axis.text.y = element_text(size = 12),
axis.title.x = element_blank(),
axis.title.y = element_blank(),
legend.position = "right") +
coord_fixed()
df %>%
filter(counts_profileVisits < 100000) %>%
ggplot(aes(x = counts_profileVisits, y = counts_kisses)) +
geom_point(aes(fill = factor(has_emoji), size = counts_g), pch = 21, alpha = 0.8, colour = "white") +
scale_fill_manual(values = c("#1beaa7", "#8c2aef"), name = "Has Emoji", labels = c("No Emoji", "Contains Emoji")) +
scale_size(range = c(1, 6)) +
labs(x = "Profile Visits Count", y = "Number of Kisses", size = "Group Interactions", fill = "Contains Emoji") +
th +
geom_smooth(aes(colour = factor(has_emoji)), method = "loess", se = FALSE) +
scale_colour_manual(values = c("#1beaa7", "#8c2aef"), name = "Has Emoji", labels = c("No Emoji", "Contains Emoji"))
plot1 <- df %>%
filter(counts_kissesStd < 2, !is.na(night_owl), !is.na(has_social)) %>%
mutate(has_emoji = factor(has_emoji, labels = c("No", "Yes")),
night_owl = factor(night_owl, labels = c("No", "Yes")),
has_social = factor(has_social, labels = c("No", "Yes"))) %>%
pivot_longer(cols = c(has_emoji, has_social), names_to = "Factor", values_to = "Value") %>%
mutate(Factor = recode(Factor,
has_emoji = "Emoji",
has_social = "Social Media")) %>%
ggplot(aes(x = Value, y = counts_kissesStd, fill = Value)) +
geom_violin(colour = "white", alpha = 0.8) +
geom_jitter(colour = "#00c2ff", alpha = 0.3, size = 0.5) +
scale_fill_manual(values = c("#1beaa7", "#8c2aef")) +
facet_wrap(~ Factor, scales = "free", strip.position = "top") +
labs(x = "", y = "Profile Kisses Count (Standardised)", fill = "") +
th +
theme(
strip.background = element_blank(),
strip.text = element_text(face = "bold", size = 14),
axis.text.x = element_blank(),
legend.position = "bottom"
) +
scale_y_continuous(breaks = c(-1, 0, 1, 2))
plot2 <- df %>%
filter(counts_profileVisitsStd < 2, !is.na(night_owl), !is.na(isOnline)) %>%
mutate(night_owl = factor(night_owl, labels = c("No", "Yes")),
isOnline = factor(isOnline, labels = c("No", "Yes"))) %>%
pivot_longer(cols = c(night_owl, isOnline), names_to = "Factor", values_to = "Value") %>%
mutate(Factor = recode(Factor,
night_owl = "Night Owl",
isOnline = "Online")) %>%
ggplot(aes(x = Value, y = counts_profileVisitsStd, fill = Value)) +
geom_violin(colour = "white", alpha = 0.8) +
geom_jitter(colour = "#00c2ff", alpha = 0.3, size = 0.5) +
scale_fill_manual(values = c("#1beaa7", "#8c2aef")) +
facet_wrap(~ Factor, scales = "free", strip.position = "top") +
labs(x = "", y = "Profile Visits Count (Standardised)", fill = "") +
th +
theme(
strip.background = element_blank(),
strip.text = element_text(face = "bold", size = 14),
axis.text.x = element_blank(),
legend.position = "bottom"
) +
scale_y_continuous(breaks = c(-1, 0, 1, 2))
plot1
plot2
# Replace NA values with an empty string
df$bio[is.na(df$bio)] <- ""
# Add a new column for bio length
df <- df %>%
mutate(bio_length = str_length(bio))
# Density plot of bio lengths
densplot <- df %>%
filter(bio_length < 102) %>%
ggplot(aes(x=bio_length)) +
geom_density(fill="#1beaa7", alpha=0.8, color = "white") +
labs(x = "Bio Length (Complexity)", y = "Density") +
th
# Add a new standardized column for bio length
scatplot <- df %>%
filter(bio_length < 102) %>%
mutate(bio_lengthStd = scale(bio_length)) %>%
filter(bio_lengthStd > 0, counts_kissesStd > 0) %>%
ggplot(aes(x=bio_lengthStd, y=counts_kissesStd)) +
scale_fill_manual(values = c("#1beaa7", "#8c2aef")) +
geom_point(aes(fill = factor(has_emoji)), pch = 21, alpha = 0.8, colour = "white", show.legend = FALSE) +
labs(x = "Standardized Bio Length (Complexity)", y = "Standardized Counts of Kisses") +
th +
geom_smooth(aes(colour = factor(has_emoji)), method = "lm", se = FALSE) +
scale_colour_manual(values = c("#1beaa7", "#8c2aef"), name = "Has Emoji", labels = c("No Emoji", "Contains Emoji"))
densplot
scatplot
# Note: commented out, due to costs associated with geocoding through the API
# df_city <- df %>%
#   select(c(city, country, counts_profileVisits)) %>%
#   mutate(address = paste0(city, ", ", country)) %>%
#   group_by(address) %>%
#   summarise(mean_profile_views = mean(counts_profileVisits, na.rm = TRUE))
#
# df_city <- df_city %>%
#   mutate(geocode_data = map(address, ~geocode(.x, source = "google", output = "latlon")),
#          lon = map_dbl(geocode_data, "lon"),
#          lat = map_dbl(geocode_data, "lat"))
#
# write_csv(df_city, "geocode_latlon.csv")
df_city <- read_excel("geocode_latlon.xlsx")
df_city <- df_city %>%
mutate(mean_profile_views = as.numeric(mean_profile_views),
lat = as.numeric(lat),
lon = as.numeric(lon)) %>%
filter(!is.na(lon),
mean_profile_views > 0,
lon > -90 & lon < 100,
lat > 0)
# Filter by countries after data cleaning and transformation
df_city <- df_city %>%
filter(substr(address, nchar(address) - 1, nchar(address)) %in% eu_countries$code | address == "UK"| address == "CZ" | address == "CH")
world <- map_data("world") %>%
filter(region %in% eu_countries$name | region == "UK" | region == "Czech Republic" | region == "Switzerland")
# Creating ggplot with map
map_bg <- ggplot(data = world) +
geom_polygon(aes(x = long, y = lat, group = group), fill = "white", colour = "#000123") +
coord_map() +
theme_void()
# Adding scatterplot on the map
views <- map_bg +
geom_point(data = df_city, aes(x = lon, y = lat, color = mean_profile_views, size = mean_profile_views), alpha = 0.8) +
scale_colour_gradient(
name = 'Mean Profile Views',
limits = range(df_city$mean_profile_views),
low = "#8c2aef",
high = "#1beaa7"
) +
scale_size_continuous(guide = "none", range = c(1, 8)) +
theme(plot.background = element_rect(fill = "#000123", color = "#000123"),
panel.background = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.text = element_blank(),
legend.key = element_rect(fill = "#000123", color = "#000123"),
legend.background = element_rect(fill = "#000123"),
legend.text = element_text(colour = "white"),
legend.title = element_text(colour = "white", face = "bold"))
# Group by country and calculate mean profile views
df_city_grouped <- df_city %>%
mutate(country_code = substr(address, nchar(address) - 1, nchar(address))) %>%
group_by(country_code) %>%
summarise(mean_profile_views = mean(mean_profile_views, na.rm = TRUE))
# Convert two-letter country codes to full country names
df_city_grouped <- left_join(df_city_grouped, eu_countries, by = c("country_code" = "code"))
# Join with the 'world' dataframe
world <- left_join(world, df_city_grouped, by = c("region" = "name"))
world <- world %>%
filter(!is.na(mean_profile_views))
# Create the choropleth map
choropleth <- map_bg +
geom_polygon(data = world, aes(x = long, y = lat, fill = mean_profile_views, group = group), color = "#000123") +
scale_fill_gradient(name = 'Mean Profile Views',
low = "#8c2aef",
high = "#1beaa7",
na.value = "") +
theme(plot.background = element_rect(fill = "#000123", color = "#000123"),
legend.key = element_rect(fill = "#000123", color = "#000123"),
legend.background = element_rect(fill = "#000123"),
legend.text = element_text(colour = "white"),
legend.title = element_text(colour = "white", face = "bold"))
views <- ggdraw(views) + theme(panel.background = element_rect(fill = "#000123", colour = "#000123"))
choropleth <- ggdraw(choropleth) + theme(panel.background = element_rect(fill = "#000123", colour = "#000123"))
print(views)
print(choropleth)
# Count the number of users per country in the 'df' dataframe
df_country_users <- df %>%
group_by(country) %>%
summarise(num_users = n())
# Convert two-letter country codes to full country names in df_country_users
df_country_users <- left_join(df_country_users, eu_countries, by = c("country" = "code"))
# Summarise mean_profile_views per country in df_city dataframe
df_city_grouped <- df_city %>%
mutate(country_code = substr(address, nchar(address) - 1, nchar(address))) %>%
group_by(country_code) %>%
summarise(mean_profile_views = mean(mean_profile_views, na.rm = TRUE))
# Join df_city_grouped with df_country_users to add the number of users per country
df_city_grouped <- left_join(df_city_grouped, df_country_users, by = c("country_code" = "country"))
# Create the lollipop chart with number of users and colored by mean profile views
ggplot(df_city_grouped, aes(x = reorder(name, -num_users), y = num_users)) +
geom_segment(aes(xend = name, yend = 0), color = "white") +
geom_point(aes(color = mean_profile_views), size = 3, alpha = 0.8) +
coord_flip() +
scale_color_gradient(name = 'Mean Profile Views', low = "#8c2aef", high = "#1beaa7") +
xlab("") +
ylab("Number of Users") + th +
theme(legend.position = "right",
panel.grid.major = element_blank(),
panel.grid.minor = element_blank())
verified_shareenabled <- df %>%
filter(shareProfileEnabled > 0) %>%
ggplot(aes(x=counts_profileVisits, y=counts_kisses)) +
scale_fill_manual(values = c("#1beaa7", "#8c2aef")) +
geom_point(aes(fill = factor(verified)), pch = 21, alpha = 0.8, colour = "white", show.legend = FALSE) +
labs(x = "Profile Visits Count", y = "Number of Kisses") +
th +
geom_smooth(aes(colour = factor(verified)), method = "lm", se = FALSE) +
scale_colour_manual(values = c("#1beaa7", "#8c2aef"), name = "Verification Status", labels = c("Unverified", "Verified")) +
theme(legend.position = "bottom") +
labs(title = "Share Profile Enabled")
verified_sharedisabled <- df %>%
filter(shareProfileEnabled < 1) %>%
ggplot(aes(x=counts_profileVisits, y=counts_kisses)) +
scale_fill_manual(values = c("#1beaa7", "#8c2aef")) +
geom_point(aes(fill = factor(verified)), pch = 21, alpha = 0.8, colour = "white", show.legend = FALSE) +
labs(x = "Profile Visits Count", y = "Number of Kisses") +
th +
geom_smooth(aes(colour = factor(verified)), method = "lm", se = FALSE) +
scale_colour_manual(values = c("#1beaa7", "#8c2aef"), name = "Verification Status", labels = c("Unverified", "Verified")) +
theme(legend.position = "bottom") +
labs(title = "Share Profile Disabled")
print(verified_shareenabled)
print(verified_sharedisabled)
agevisits <- df %>%
ggplot(aes(x=age, y=counts_profileVisits)) +
geom_point(color = "#1beaa7") +
labs(x = "Age", y = "Counts Profile Visits") +
th +
geom_smooth(color = "white", method = "lm", se = FALSE)
agekisses <- df %>%
ggplot(aes(x=age, y=counts_kisses)) +
geom_point(color = "#8c2aef") +
labs(x = "Age", y = "Number of Kisses") +
th +
geom_smooth(color = "white", method = "lm", se = FALSE)
print(agevisits)
print(agekisses)
df_long <- df %>%
pivot_longer(cols = starts_with("lang_"),
names_to = "language",
values_to = "spoken") %>%
filter(spoken == TRUE) %>%
mutate(language = str_remove(language, "lang_"),
language = recode(language,
"de" = "German",
"en" = "English",
"es" = "Spanish",
"fr" = "French",
"it" = "Italian",
"pt" = "Portuguese"))
df_long %>%
filter(language != "count", counts_kisses < 1000) %>%
ggplot(aes(x = counts_kisses, y = language, fill = language)) +
geom_density_ridges(scale = 3, rel_min_height = 0.01, colour = "white", alpha = 0.8) +
scale_fill_manual(values = palette) +
geom_vline(aes(xintercept = 157.0227), linetype = "dashed", colour = "white") +
theme_ridges() +
th +
theme(legend.position = "none") +
labs(x = "Profile Kisses Count", y = "Language") +
annotate("text", x = 170, y = Inf, label = "Mean Kisses Received (~160)", vjust = 2, hjust = 0, size = 4, colour = "white")
df_summary <- df %>%
group_by(counts_pictures, has_social) %>%
summarise(mean_kisses = mean(counts_kisses, na.rm = TRUE),
.groups = "drop")
df_summary %>%
filter(counts_pictures < 19 & counts_pictures > 0) %>%
ggplot(aes(x = as.factor(counts_pictures), y = mean_kisses, colour = factor(has_social), group = (has_social))) +
geom_line(size = 1) +
geom_point() +
scale_colour_manual(values = c("#1beaa7", "#8c2aef"),
name = "Social Media",
labels = c("No", "Yes")) +
labs(x = "Pictures Count",
y = "Mean Profile Kisses Count",
colour = "Contains Social Media") +
th +
theme(legend.position = "right")
# Set seed for reproducibility
set.seed(777)
# Define training and testing sets for profile visits prediction
split_visits <- initial_split(df, prop = 0.7, strata = "Profile_Views")
training_visits <- training(split_visits)
testing_visits <- testing(split_visits)
# Set seed for reproducibility
set.seed(777)
# Define training and testing sets for likes prediction
split_kisses <- initial_split(df, prop = 0.7, strata = "Profile_Likes")
training_kisses <- training(split_kisses)
testing_kisses <- testing(split_kisses)
# Define the tuning grid
tuneGrid <- expand.grid(cp = seq(0.001, 0.1, by = 0.001))
# Define control parameters for train function
fitControl <- trainControl(method = "cv", number = 10) # 10-fold cross validation
# Train the model
visits_tree_tuned <- train(Profile_Views ~ isOnline*night_owl + age*genderLooking + verified + isMobile,
data = training_visits,
method = "rpart",
trControl = fitControl,
tuneGrid = tuneGrid)
# Train the model
kisses_tree_tuned <- train(Profile_Likes ~  Profile_Views*counts_g + bio_length*(has_emoji + has_social) + counts_pictures + lang_count + flirtInterests_chat + flirtInterests_date + flirtInterests_friends + counts_details + isMobile +  verified*shareProfileEnabled,
data = training_visits,
method = "rpart",
trControl = fitControl,
tuneGrid = tuneGrid)
print(visits_tree_tuned)
# Predict profile visits using the tuned model
visits_pred <- predict(visits_tree_tuned, newdata = testing_visits)
# Predict profile likes using the tuned model
kisses_pred <- predict(kisses_tree_tuned, newdata = testing_kisses)
# Compute accuracy for a classification problem
accuracy_visits <- sum(visits_pred == testing_visits$Profile_Views) / nrow(testing_visits)
# Compute root mean squared error (RMSE) for a regression problem
accuracy_kisses <- sum(kisses_pred == testing_visits$Profile_Views) / nrow(testing_visits)
rpart.plot(visits_tree_tuned$finalModel)
plot(visits_tree_tuned)
# Predict on test set
predictions <- predict(visits_tree_tuned, newdata = testing_kisses)
# Create data frame
pred_df <- data.frame(Predicted = predictions, Actual = testing_visits$Profile_Views)
# Define the tuning grid
tuneGrid <- expand.grid(cp = seq(0.001, 0.1, by = 0.001))
# Define control parameters for train function
fitControl <- trainControl(method = "cv", number = 10) # 10-fold cross validation
# Train the model
kisses_tree_tuned <- train(Profile_Likes ~  Profile_Views*counts_g + bio_length*(has_emoji + has_social) + counts_pictures + lang_count + flirtInterests_chat + flirtInterests_date + flirtInterests_friends + counts_details + isMobile +  verified*shareProfileEnabled,
data = training_visits,
method = "rpart",
trControl = fitControl,
tuneGrid = tuneGrid)
print(kisses_tree_tuned)
rpart.plot(kisses_tree_tuned$finalModel)
plot(kisses_tree_tuned)
# Predict on test set
predictions <- predict(kisses_tree_tuned, newdata = testing_kisses)
# Create data frame
pred_df <- data.frame(Predicted = predictions, Actual = testing_kisses$Profile_Likes)
# Plot
ggplot(pred_df, aes(x = Actual, y = Predicted)) +
geom_point(color = "#1beaa7") +
geom_abline(color = "white") +
th
# Set seed for reproducibility
set.seed(777)
# Filter out NA values
training_visits <- training_visits %>% filter(!is.na(night_owl))
# Random Forest model for profile visits
visits_rf <- randomForest(formula = Profile_Views ~ isOnline + night_owl + age + genderLooking,
data = training_visits,
importance = TRUE,
ntree = 500)
# View model summary
visits_rf
# Random Forest model for profile likes
kisses_rf <- randomForest(formula = Profile_Likes ~ has_emoji*flirtInterests_chat + has_social*counts_pictures + Profile_Views + lang_count + flirtInterests_date + flirtInterests_friends + counts_details,
data = training_kisses,
importance = TRUE,
ntree = 500)
# View model summary
kisses_rf
# Predict on test data
visits_rf_pred <- predict(visits_rf, newdata = testing_visits)
kisses_rf_pred <- predict(kisses_rf, newdata = testing_kisses)
# Confusion matrices
confusionMatrix(visits_rf_pred, testing_visits$Profile_Views)
confusionMatrix(kisses_rf_pred, testing_kisses$Profile_Likes)
# Predict on test set
predictions <- predict(visits_tree_tuned, newdata = testing_kisses)
# Create data frame
pred_df <- data.frame(Predicted = predictions, Actual = testing_visits$Profile_Views)
# Predict on test set
predictions <- predict(visits_tree_tuned, newdata = testing_visits)
# Create data frame
pred_df <- data.frame(Predicted = predictions, Actual = testing_visits$Profile_Views)
# Predict on test set
predictions <- predict(visits_tree_tuned, newdata = testing_visits)
# Create data frame
pred_df <- data.frame(Predicted = predictions, Actual = testing_visits$Profile_Views)
# Predict profile visits using the tuned model
visits_pred <- predict(visits_tree_tuned, newdata = testing_visits)
# Predict profile likes using the tuned model
kisses_pred <- predict(kisses_tree_tuned, newdata = testing_kisses)
# Compute accuracy for a classification problem
accuracy_visits <- sum(visits_pred == testing_visits$Profile_Views) / nrow(testing_visits)
# Compute root mean squared error (RMSE) for a regression problem
accuracy_kisses <- sum(kisses_pred == testing_visits$Profile_Views) / nrow(testing_visits)
rpart.plot(visits_tree_tuned$finalModel)
plot(visits_tree_tuned)
# Predict on test set
predictions <- predict(visits_tree_tuned, newdata = testing_visits)
# Create data frame
pred_df <- data.frame(Predicted = predictions, Actual = testing_visits$Profile_Views)
sum(is.na(testing_visits$Profile_Views))
length(predictions)
nrow(testing_visits)
# Predict profile visits using the tuned model
visits_pred <- predict(visits_tree_tuned, newdata = testing_visits)
# Create data frame
pred_df <- data.frame(Predicted = visits_pred, Actual = testing_visits$Profile_Views)
# Compute accuracy for a classification problem
accuracy_visits <- sum(visits_pred == testing_visits$Profile_Views) / nrow(testing_visits)
rpart.plot(visits_tree_tuned$finalModel)
visits_tree_tuned$finalModel
# Predict profile visits using the tuned model
visits_pred <- predict(visits_tree_tuned, newdata = testing_visits)
# Create confusion matrix
confusionMatrix(table(Predicted = visits_pred, Reference = testing_visits$Profile_Views))
# Predict profile visits using the tuned model
visits_pred <- predict(visits_tree_tuned, newdata = testing_visits)
# Compute accuracy for a classification problem
accuracy_visits <- sum(visits_pred == testing_visits$Profile_Views) / nrow(testing_visits)
# Create confusion matrix
confusionMatrix(table(Predicted = visits_pred, Reference = testing_visits$Profile_Views))
# Define the tuning grid
tuneGrid <- expand.grid(cp = seq(0.001, 0.1, by = 0.001))
# Define control parameters for train function
fitControl <- trainControl(method = "cv", number = 10) # 10-fold cross validation
# Train the model
visits_tree_tuned <- train(Profile_Views ~ isOnline*night_owl + age*genderLooking + verified + isMobile,
data = training_visits,
method = "rpart",
trControl = fitControl,
tuneGrid = tuneGrid)
df <- df[complete.cases(df[,c('isOnline', 'night_owl', 'age', 'genderLooking', 'verified', 'isMobile')]), ]
# Set seed for reproducibility
set.seed(777)
# Define training and testing sets for profile visits prediction
split_visits <- initial_split(df, prop = 0.7, strata = "Profile_Views")
training_visits <- training(split_visits)
testing_visits <- testing(split_visits)
# Set seed for reproducibility
set.seed(777)
# Define training and testing sets for likes prediction
split_kisses <- initial_split(df, prop = 0.7, strata = "Profile_Likes")
training_kisses <- training(split_kisses)
testing_kisses <- testing(split_kisses)
# Define the tuning grid
tuneGrid <- expand.grid(cp = seq(0.001, 0.1, by = 0.001))
# Define control parameters for train function
fitControl <- trainControl(method = "cv", number = 10) # 10-fold cross validation
# Train the model
visits_tree_tuned <- train(Profile_Views ~ isOnline*night_owl + age*genderLooking + verified + isMobile,
data = training_visits,
method = "rpart",
trControl = fitControl,
tuneGrid = tuneGrid)
plot(visits_tree_tuned)
rpart.plot(visits_tree_tuned$finalModel)
# Predict profile visits using the tuned model
visits_pred <- predict(visits_tree_tuned, newdata = testing_visits)
# Compute accuracy for a classification problem
accuracy_visits <- sum(visits_pred == testing_visits$Profile_Views) / nrow(testing_visits)
# Create confusion matrix
confusionMatrix(table(Predicted = visits_pred, Reference = testing_visits$Profile_Views))
visits_tree_tuned$finalModel
# Predict profile visits using the tuned model
visits_pred <- predict(visits_tree_tuned, newdata = testing_visits)
# Create confusion matrix
confusionMatrix(table(Predicted = visits_pred, Reference = testing_visits$Profile_Views))
# Define the tuning grid
tuneGrid <- expand.grid(cp = seq(0.001, 0.1, by = 0.001))
# Define control parameters for train function
fitControl <- trainControl(method = "cv", number = 10) # 10-fold cross validation
# Train the model
kisses_tree_tuned <- train(Profile_Likes ~  Profile_Views*counts_g + bio_length*(has_emoji + has_social) + counts_pictures + lang_count + flirtInterests_chat + flirtInterests_date + flirtInterests_friends + counts_details + isMobile +  verified*shareProfileEnabled,
data = training_visits,
method = "rpart",
trControl = fitControl,
tuneGrid = tuneGrid)
print(kisses_tree_tuned)
# Predict profile likes using the tuned model
kisses_pred <- predict(kisses_tree_tuned, newdata = testing_kisses)
confusionMatrix(table(Predicted = kisses_pred, Reference = testing_kisses$Profile_Likes))
# Define the tuning grid
tuneGrid <- expand.grid(cp = seq(0.001, 0.1, by = 0.001))
# Define control parameters for train function
fitControl <- trainControl(method = "cv", number = 10) # 10-fold cross validation
# Train the model
kisses_tree_tuned <- train(Profile_Likes ~  Profile_Views*counts_g + bio_length*(has_emoji + has_social) + counts_pictures + lang_count + flirtInterests_chat + flirtInterests_date + flirtInterests_friends + counts_details + isMobile +  verified*shareProfileEnabled,
data = training_visits,
method = "rpart",
trControl = fitControl,
tuneGrid = tuneGrid)
plot(kisses_tree_tuned)
# Define the tuning grid
tuneGrid <- expand.grid(cp = seq(0.001, 0.1, by = 0.001))
# Define control parameters for train function
fitControl <- trainControl(method = "cv", number = 10) # 10-fold cross validation
# Train the model
visits_tree_tuned <- train(Profile_Views ~ isOnline*night_owl + age*genderLooking + verified + isMobile,
data = training_visits,
method = "rpart",
trControl = fitControl,
tuneGrid = tuneGrid)
plot(visits_tree_tuned)
rpart.plot(visits_tree_tuned$finalModel)
# Predict profile visits using the tuned model
visits_pred <- predict(visits_tree_tuned, newdata = testing_visits)
confusionMatrix(table(Predicted = visits_pred, Reference = testing_visits$Profile_Views))
rpart.plot(kisses_tree_tuned$finalModel)
kisses_tree_tuned$finalModel
rpart.plot(kisses_tree_tuned$finalModel)
