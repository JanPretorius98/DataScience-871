# Shrinkage methods

# Housekeeping
pacman::p_load(dplyr, ggplot2, rsample, caret, glmnet, vip, tidyverse, pdp, AmesHousing)

# Create training sample
set.seed(123)
ames <- AmesHousing::make_ames()
split  <- initial_split(ames, prop = 0.7, strata = "Sale_Price")
ames_train  <- training(split)
ames_test   <- testing(split)

# Build linear model on data
model1 <- lm(Sale_Price ~ Gr_Liv_Area, data = ames_train)
model2 <- lm(Sale_Price ~ Gr_Liv_Area + Year_Built, data = ames_train)
model2 <- lm(Sale_Price ~ ., data = ames_train)

# Build linear ML model
set.seed(123)  
(cv_model1 <- train(form = Sale_Price ~ Gr_Liv_Area, 
                    data = ames_train, 
                    method = "lm",
                    trControl = trainControl(method = "cv", number = 10)
))

  # MLR
set.seed(123)  
(cv_model2 <- train(form = Sale_Price ~ Gr_Liv_Area + Year_Built, 
                    data = ames_train, 
                    method = "lm",
                    trControl = trainControl(method = "cv", number = 10)
))

# Create training  feature matrices
# we use model.matrix(...)[, -1] to discard the intercept
X <- model.matrix(Sale_Price ~ ., ames_train)[, -1]
# transform y with log transformation
Y <- log(ames_train$Sale_Price)

# Apply CV ridge regression to Ames data
ridge <- cv.glmnet(
  x = X,
  y = Y,
  alpha = 0)
# Apply CV lasso regression to Ames data
lasso <- cv.glmnet(
  x = X,
  y = Y,
  alpha = 1)
