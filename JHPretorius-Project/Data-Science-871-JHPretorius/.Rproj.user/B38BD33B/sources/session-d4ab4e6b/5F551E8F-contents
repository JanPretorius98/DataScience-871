---
title: "Transform Data"
author: "JH Pretorius"
date: "2023-05-03"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r housekeeping, results='hide', warning=FALSE}
library(tidyverse)
library(readxl)
library(writexl)
library(vars)
library(urca)
library(tsDyn)
library(zoo)
library(tseries)
library(xts)
library(seasonal)
library(car)
library(lmtest)

rm(list = ls()) #Clear environment
```

#   Plot themes and palette

```{r results='hide', warning=FALSE}

# Define plot themes and palettes----
palette_2 <- c("#378490","#28b886")
palette_3 <- c("#28b886", "#F44743", "#e7d684")
palette_5 <- c("#378490", "#28b886", "#e7d684", "#f4a057", "#F44743")
palette_8 <- c("#378490", "#28b886", "#78C19C", "#E9DDA3","#e7d684", "#f4a057", "#F27B60", "#F44743")

th <- theme(legend.position = "bottom",
            panel.background = element_blank(),
            plot.background = element_rect(fill = "white", color = "white"),
            panel.grid.major = element_line(color="#808080", size = 0.1),
            panel.grid.minor = element_line(color="#808080", size = 0.1),
            axis.title.x=element_text(colour="black", size = 12,family = "Times New Roman", vjust=-2,hjust=0.5),
            axis.title.y=element_text(colour="black", size = 12,family = "Times New Roman",vjust = 3,hjust=0.5),
            axis.text.y=element_text(colour ="black", size = 10, family = "Times New Roman"),
            axis.text.x=element_text(colour="black", size = 10,family = "Times New Roman"),
            plot.margin = unit(c(0.5,0.5,0.5,0.5), "cm"),
            plot.title = element_text(colour="black", size = 16,family = "Times New Roman",hjust=0.5, face = "bold"),
            plot.subtitle = element_text(colour="black", size = 14,family = "Times New Roman"),
            plot.caption = element_text(colour="black", size = 10,family = "Times New Roman"),
            legend.text = element_text(colour="black", size = 12,family = "Times New Roman"),
            legend.title = element_text(colour="black", size = 12,family = "Times New Roman", hjust=3, face = "bold"),
            axis.ticks = element_blank(),
            strip.background = element_blank(),
            strip.text = element_text(colour="black", size = 14,family = "Times New Roman"))

```

#   Replicate MacDonald & Ricci Graphics

```{r results='hide', warning=FALSE}
# First import the data set
MAC_RIC_DATA <- read_excel("/Users/janhendrikpretorius/Library/CloudStorage/OneDrive-StellenboschUniversity/Masters-2023/Modules/Econometrics/Time-Series/Research Assignment/Working data/MAC_RIC_DATA_adjusted.xlsx")
MAC_RIC_DATA$DATE <- as.yearqtr(MAC_RIC_DATA$DATE, format = "%Y Q%q")
# Plot LREERS
LREERS <- MAC_RIC_DATA %>% 
  ggplot(aes(x=DATE, y=LREERS)) + 
  geom_line() +
  th

ggsave("/Users/janhendrikpretorius/Library/CloudStorage/OneDrive-StellenboschUniversity/Masters-2023/Modules/Econometrics/Time-Series/Research Assignment/Replicated Plots/LREERS.png", plot = LREERS, height = 3, width = 5)

RIRR <- MAC_RIC_DATA %>% 
  ggplot(aes(x=DATE, y=RIRR)) +
  geom_line() +
  th

ggsave("/Users/janhendrikpretorius/Library/CloudStorage/OneDrive-StellenboschUniversity/Masters-2023/Modules/Econometrics/Time-Series/Research Assignment/Replicated Plots/RIRR.png", plot = RIRR, height = 3, width = 5)

LRGDPPCR <- MAC_RIC_DATA %>% 
  ggplot(aes(x=DATE, y=LRGDPPCR)) +
  geom_line() +
  th

ggsave("/Users/janhendrikpretorius/Library/CloudStorage/OneDrive-StellenboschUniversity/Masters-2023/Modules/Econometrics/Time-Series/Research Assignment/Replicated Plots/LRGDPPCRS.png", plot = LRGDPPCR, height = 3, width = 5)

LPR2COMM5 <- MAC_RIC_DATA %>% 
  ggplot(aes(x=DATE, y=LPR2COMM5)) +
  geom_line() +
  th

ggsave("/Users/janhendrikpretorius/Library/CloudStorage/OneDrive-StellenboschUniversity/Masters-2023/Modules/Econometrics/Time-Series/Research Assignment/Replicated Plots/LPR2COMM5.png", plot = LPR2COMM5, height = 3, width = 5)

OPENY <- MAC_RIC_DATA %>% 
  ggplot(aes(x=DATE, y=OPENY)) +
  geom_line() +
  th

ggsave("/Users/janhendrikpretorius/Library/CloudStorage/OneDrive-StellenboschUniversity/Masters-2023/Modules/Econometrics/Time-Series/Research Assignment/Replicated Plots/OPENY.png", plot = OPENY, height = 3, width = 5)

FBYA <- MAC_RIC_DATA %>% 
  ggplot(aes(x=DATE, y=FBYA)) +
  geom_line() +
  th

ggsave("/Users/janhendrikpretorius/Library/CloudStorage/OneDrive-StellenboschUniversity/Masters-2023/Modules/Econometrics/Time-Series/Research Assignment/Replicated Plots/FBYA.png", plot = FBYA, height = 3, width = 5)

NFAOFPY <- MAC_RIC_DATA %>% 
  ggplot(aes(x=DATE, y=NFAOFPY)) +
  geom_line() +
  th

ggsave("/Users/janhendrikpretorius/Library/CloudStorage/OneDrive-StellenboschUniversity/Masters-2023/Modules/Econometrics/Time-Series/Research Assignment/Replicated Plots/NFAOFPY.png", plot = NFAOFPY, height = 3, width = 5)
```

#   Adjusting the data
##   Seasonally adjust with centered dummies & outlier dummies

```{r results='hide', warning=FALSE}
MAC_RIC_DATA <- read_excel("/Users/janhendrikpretorius/Library/CloudStorage/OneDrive-StellenboschUniversity/Masters-2023/Modules/Econometrics/Time-Series/Research Assignment/Working data/MAC_RIC_DATA.xlsx")
MAC_RIC_DATA$DATE <- as.yearqtr(MAC_RIC_DATA$DATE, format = "%Y Q%q")
MAC_RIC_DATA$t <- seq(1, length(MAC_RIC_DATA$DATE))

# Seasonal adjustment function
seasonally_adjust <- function(data, variables) {
  adjusted_data <- data
  for (var in variables) {
    adjustment_model <- lm(data[[var]] ~ SDUMC1 + SDUMC2 + SDUMC3 + t, data = data)
    adjusted_var <- data[[var]] - fitted(adjustment_model)
    adjusted_data[[var]] <- adjusted_var
  }
  return(adjusted_data)
}
 
# List of variables to be adjusted
variables_to_adjust <- c("LPR2COMM5", "LPRCOMM5", "LPR2COMM3", "LPRCOMM3", "LPR2GOLD", "LPRGOLD")

# Apply the seasonal adjustment function to the variables in the dataframe
MAC_RIC_DATA_adjusted <- seasonally_adjust(MAC_RIC_DATA, variables_to_adjust)

outlier_adjust <- function(data) {
  adjusted_data <- data
  adjustment_model_LREERS <- lm(LREERS ~ DUMRER1 + DUMRER2 + t, data = data)
  adjusted_data$LREERS <- data$LREERS - fitted(adjustment_model_LREERS)
  
  adjustment_model_FBYA <- lm(data$FBYA ~ DUMFBYA + t, data = data)
  adjusted_data$FBYA <- data$FBYA - fitted(adjustment_model_FBYA)
  
  adjustment_model_NFAOFPY <- lm(data$NFAOFPY ~ DUMNFAOFPY + t, data = data)
  adjusted_data$NFAOFPY <- data$NFAOFPY - fitted(adjustment_model_NFAOFPY)
  
  return(adjusted_data)
}

# Apply the outlier adjustment function to the seasonally adjusted data
MAC_RIC_DATA_adjusted_outlier <- outlier_adjust(MAC_RIC_DATA_adjusted)

```

#   Replicate MacDonald & Ricci Graphics

```{r results='hide', warning=FALSE}
# First import the data set
MAC_RIC_DATA <- read_excel("/Users/janhendrikpretorius/Library/CloudStorage/OneDrive-StellenboschUniversity/Masters-2023/Modules/Econometrics/Time-Series/Research Assignment/Working data/EXTENDED_FINAL.xlsx")
MAC_RIC_DATA$DATE <- as.yearqtr(MAC_RIC_DATA$DATE, format = "%Y Q%q")
# Plot LREERS
LREERS <- MAC_RIC_DATA %>% 
  ggplot(aes(x=DATE, y=LREERS)) + 
  geom_line(color = "#378490") +
  th

ggsave("/Users/janhendrikpretorius/Library/CloudStorage/OneDrive-StellenboschUniversity/Masters-2023/Modules/Econometrics/Time-Series/Research Assignment/Extended Plots/LREERS.png", plot = LREERS, height = 3, width = 5)

RIRR <- MAC_RIC_DATA %>% 
  ggplot(aes(x=DATE, y=RIRR)) +
  geom_line(color = "#378490") +
  th

ggsave("/Users/janhendrikpretorius/Library/CloudStorage/OneDrive-StellenboschUniversity/Masters-2023/Modules/Econometrics/Time-Series/Research Assignment/Extended Plots/RIRR.png", plot = RIRR, height = 3, width = 5)

LRGDPPCR <- MAC_RIC_DATA %>% 
  ggplot(aes(x=DATE, y=LRGDPPCR)) +
  geom_line(color = "#378490") +
  th

ggsave("/Users/janhendrikpretorius/Library/CloudStorage/OneDrive-StellenboschUniversity/Masters-2023/Modules/Econometrics/Time-Series/Research Assignment/Extended Plots/LRGDPPCRS.png", plot = LRGDPPCR, height = 3, width = 5)

LPRCOMM <- MAC_RIC_DATA %>% 
  ggplot(aes(x=DATE, y=LPRCOMM)) +
  geom_line(color = "#378490") +
  th

ggsave("/Users/janhendrikpretorius/Library/CloudStorage/OneDrive-StellenboschUniversity/Masters-2023/Modules/Econometrics/Time-Series/Research Assignment/Extended Plots/LPR2COMM5.png", plot = LPRCOMM, height = 3, width = 5)

OPENY <- MAC_RIC_DATA %>% 
  ggplot(aes(x=DATE, y=OPENY)) +
  geom_line(color = "#378490") +
  th

ggsave("/Users/janhendrikpretorius/Library/CloudStorage/OneDrive-StellenboschUniversity/Masters-2023/Modules/Econometrics/Time-Series/Research Assignment/Extended Plots/OPENY.png", plot = OPENY, height = 3, width = 5)

FBYA <- MAC_RIC_DATA %>% 
  ggplot(aes(x=DATE, y=FBYA)) +
  geom_line(color = "#378490") +
  th

ggsave("/Users/janhendrikpretorius/Library/CloudStorage/OneDrive-StellenboschUniversity/Masters-2023/Modules/Econometrics/Time-Series/Research Assignment/Extended Plots/FBYA.png", plot = FBYA, height = 3, width = 5)

NFAOFPY <- MAC_RIC_DATA %>% 
  ggplot(aes(x=DATE, y=NFAOFPY)) +
  geom_line(color = "#378490") +
  th

ggsave("/Users/janhendrikpretorius/Library/CloudStorage/OneDrive-StellenboschUniversity/Masters-2023/Modules/Econometrics/Time-Series/Research Assignment/Extended Plots/NFAOFPY.png", plot = NFAOFPY, height = 3, width = 5)
```

##   Seasonally adjust MAC_RIC_DATA by the X-13ARIMA-SEATS method

```{r results='hide', warning=FALSE}
MAC_RIC_DATA <- read_excel("/Users/janhendrikpretorius/Library/CloudStorage/OneDrive-StellenboschUniversity/Masters-2023/Modules/Econometrics/Time-Series/Research Assignment/Working data/MAC_RIC_DATA.xlsx", sheet = "Raw")

x13_adjust <- function(ts_data) {
  # Apply the X-13ARIMA-SEATS adjustment
  adjusted_data <- final(seas(ts_data))
  return(adjusted_data)
}

# Convert the dataframe to a time series object
MAC_RIC_DATA_ts <- ts(MAC_RIC_DATA[, c("LREERS", "RIRR", "LRGDPPCR", "OPENY", "FBYA", "NFAOFPY", "LPR2COMM5", "LPRCOMM5", "LPR2COMM3", "LPRCOMM3", "LPR2GOLD", "LPRGOLD")], start = c(1970, 1), frequency = 4)

# Apply the X-13ARIMA-SEATS adjustment to each variable
MAC_RIC_DATA_arima_adjust <- data.frame(
  lapply(MAC_RIC_DATA_ts, function(x) {
    x13_adjust(x)
  })
)

# Add the date column back to the adjusted dataframe
MAC_RIC_DATA_arima_adjust$DATE <- MAC_RIC_DATA$DATE
write_xlsx(MAC_RIC_DATA_arima_adjust, "/Users/janhendrikpretorius/Library/CloudStorage/OneDrive-StellenboschUniversity/Masters-2023/Modules/Econometrics/Time-Series/Research Assignment/Working data/MAC_RIC_DATA_arima_adjust.xlsx")

```

#   Replicate MacDonald & Ricci Results
##    Table 1: Using tsDyn and urca to build the VECM

```{r results='hide', warning=FALSE}
MAC_RIC_DATA <- read_excel("/Users/janhendrikpretorius/Library/CloudStorage/OneDrive-StellenboschUniversity/Masters-2023/Modules/Econometrics/Time-Series/Research Assignment/Working data/MAC_RIC_DATA.xlsx", sheet = "Raw")

# Create a new dataframe with the relevant columns
df_1 <- MAC_RIC_DATA_arima_adjust[, c("LREERS", "RIRR", "LRGDPPCR","OPENY", "FBYA", "NFAOFPY", "LPR2COMM5")]
df_2 <- MAC_RIC_DATA[, c("LREERS", "RIRR", "LRGDPPCR","OPENY", "FBYA", "NFAOFPY", "LPR2COMM5")]
df_3 <- MAC_RIC_DATA[,c("LREERS", "RIRR", "LRGDPPCR", "OPENY", "FBYA", "NFAOFPY", "LPRCOMM5")]
df_4 <- MAC_RIC_DATA[,c("LREERS", "RIRR", "LRGDPPCR", "OPENY", "FBYA", "NFAOFPY", "LPR2COMM3")]
df_5 <- MAC_RIC_DATA[,c("LREERS", "RIRR", "LRGDPPCR","OPENY", "FBYA", "NFAOFPY", "LPRCOMM3")]

exo <- MAC_RIC_DATA[,c("SDUMC1", "SDUMC2", "SDUMC3")]
exo_dum <- MAC_RIC_DATA[,c("SDUMC1", "SDUMC2", "SDUMC3", "DUMRER1", "DUMRER2", "DUMFBYA", "DUMNFAOFPY")]


# Determine number of cointegrating relationships
# Johansen test without seasonal adjustment (df_2)
vecm_2_trace <- ca.jo(df_2, type = "trace", ecdet = "const", K = 4)
vecm_2_eigen <- ca.jo(df_2, type = "eigen", ecdet = "const", K = 4)
summary(vecm_2_trace)
summary(vecm_2_eigen)

# Johansen test with seasonal dummy adjustment (df_2)
vecm_3_trace <- ca.jo(df_2, type = "trace", ecdet = "const", K = 4, dumvar = exo)
vecm_3_eigen <- ca.jo(df_2, type = "eigen", ecdet = "const", K = 4, dumvar = exo)
summary(vecm_3_trace)
summary(vecm_3_eigen)

# Johansen test with X-13ARIMA-SEATS (df_1)
vecm_1_trace <- ca.jo(df_1, type = "trace", ecdet = "const", K = 4)
vecm_1_eigen <- ca.jo(df_1, type = "eigen", ecdet = "const", K = 4)
summary(vecm_1_trace)
summary(vecm_1_eigen)

# Johansen test with seasonal and outlier dummy adjustment (df_2)
vecm_4_trace <- ca.jo(df_2, type = "trace", ecdet = "const", K = 4, dumvar = exo_dum)
vecm_4_eigen <- ca.jo(df_2, type = "eigen", ecdet = "const", K = 4, dumvar = exo_dum)
summary(vecm_4_trace)
summary(vecm_4_eigen)

# Johansen test with LPRCOMM5 (df_3)
vecm_5_trace <- ca.jo(df_3, type = "trace", ecdet = "const", K = 4, dumvar = exo)
vecm_5_eigen <- ca.jo(df_3, type = "eigen", ecdet = "const", K = 4, dumvar = exo)
summary(vecm_5_trace)
summary(vecm_5_eigen)

# Johansen test with LPR2COMM3 (df_4)
vecm_6_trace <- ca.jo(df_4, type = "trace", ecdet = "const", K = 4, dumvar = exo)
vecm_6_eigen <- ca.jo(df_4, type = "eigen", ecdet = "const", K = 4, dumvar = exo)
summary(vecm_6_trace)
summary(vecm_6_eigen)

# Johansen test with LPRCOMM3 (df_5)
vecm_7_trace <- ca.jo(df_5, type = "trace", ecdet = "const", K = 4, dumvar = exo)
vecm_7_eigen <- ca.jo(df_5, type = "eigen", ecdet = "const", K = 4, dumvar = exo)
summary(vecm_7_trace)
summary(vecm_7_eigen)


# Estimate the VECM
# No adjustment
vecm_2 <- VECM(df_2, 4, r = 1, estim = "ML", include = ("const"))
summary(vecm_2)
# Seasonal dummies
vecm_3 <- VECM(df_2, 4, r = 1, estim = "ML", include = ("const"), exogen = exo)
summary(vecm_3)
# X-13ARIMA-SEATS (df_1)
vecm_1 <- VECM(df_1, 4, r = 1, estim = "ML", include = ("const"))
summary(vecm_1)
# Seasonal and outlier dummies
vecm_4 <- VECM(df_2, 4, r = 1, estim = "ML", include = ("const"), exogen = exo_dum)
summary(vecm_4)
# Other commodity
vecm_5 <- VECM(df_3, 4, r = 1, estim = "ML", include = ("const"), exogen = exo)
summary(vecm_5)
# Other commodity
vecm_6 <- VECM(df_4, 4, r = 1, estim = "ML", include = ("const"), exogen = exo)
summary(vecm_6)
# Other commodity
vecm_7 <- VECM(df_5, 4, r = 1, estim = "ML", include = ("const"), exogen = exo)
summary(vecm_7)

```

##    Table 2: Diagnostic test

```{r results='hide', warning=FALSE}
# We are looking at regression 1, which was estimated using vecm_3_trace/eigen
# We must also estimate the underlying VAR to run some of the other tests

var_1 <- VAR(df_2, p = 4, type = "const", exogen = exo)

# Exclusion tests: Wald Test
wald_result <- causality(var_1, cause = "NFAOFPY")
print(wald_result)

# Serial correlation
var_1 <- vec2var(vecm_3_trace, r = 1)
serial_1 <-  serial.test(var_1, lags.pt = 5, type = "PT.asymptotic")
serial_1

# ARCH Effects
arch_1 <- arch.test(var_1, lags.multi = 15, multivariate.only = TRUE)
arch_1

# Normality of Residuals
norm_1 <- normality.test(var_1, multivariate.only = TRUE)
norm_1

# Impulse response functions
irf_1 <- irf(var_1, impulse = "LRGDPPCR", response = "LREERS", n.ahead = 20)
plot(irf_1)

# Define the A matrices
A_LREERS <- matrix(c( 0, 1, 0, 0, 0, 0, 0,
                      0, 0, 1, 0, 0, 0, 0,
                      0, 0, 0, 1, 0, 0, 0,
                      0, 0, 0, 0, 1, 0, 0,
                      0, 0, 0, 0, 0, 1, 0,
                      0, 0, 0, 0, 0, 0, 1), nrow = 7, ncol = 6)

A_RIRR <- matrix(c(   1, 0, 0, 0, 0, 0, 0,
                      0, 0, 1, 0, 0, 0, 0,
                      0, 0, 0, 1, 0, 0, 0,
                      0, 0, 0, 0, 1, 0, 0,
                      0, 0, 0, 0, 0, 1, 0,
                      0, 0, 0, 0, 0, 0, 1), nrow = 7, ncol = 6)

A_LRGDPPCR <- matrix(c(1, 0, 0, 0, 0, 0, 0,
                       0, 1, 0, 0, 0, 0, 0,
                       0, 0, 0, 1, 0, 0, 0,
                       0, 0, 0, 0, 1, 0, 0,
                       0, 0, 0, 0, 0, 1, 0,
                       0, 0, 0, 0, 0, 0, 1), nrow = 7, ncol = 6)

A_OPENY <- matrix(c(1, 0, 0, 0, 0, 0, 0,
                    0, 1, 0, 0, 0, 0, 0,
                    0, 0, 1, 0, 0, 0, 0,
                    0, 0, 0, 0, 1, 0, 0,
                    0, 0, 0, 0, 0, 1, 0,
                    0, 0, 0, 0, 0, 0, 1), nrow = 7, ncol = 6)

A_FBYA <- matrix(c(1, 0, 0, 0, 0, 0, 0,
                   0, 1, 0, 0, 0, 0, 0,
                   0, 0, 1, 0, 0, 0, 0,
                   0, 0, 0, 1, 0, 0, 0,
                   0, 0, 0, 0, 0, 1, 0,
                   0, 0, 0, 0, 0, 0, 1), nrow = 7, ncol = 6)

A_NFAOFPY <- matrix(c(1, 0, 0, 0, 0, 0, 0,
                      0, 1, 0, 0, 0, 0, 0,
                      0, 0, 1, 0, 0, 0, 0,
                      0, 0, 0, 1, 0, 0, 0,
                      0, 0, 0, 0, 1, 0, 0,
                      0, 0, 0, 0, 0, 0, 1), nrow = 7, ncol = 6)

A_LPR2COMM5 <- matrix(c(1, 0, 0, 0, 0, 0, 0,
                        0, 1, 0, 0, 0, 0, 0,
                        0, 0, 1, 0, 0, 0, 0,
                        0, 0, 0, 1, 0, 0, 0,
                        0, 0, 0, 0, 1, 0, 0,
                        0, 0, 0, 0, 0, 1, 0), nrow = 7, ncol = 6)

# Perform the weak exogeneity test (Likelihood Ratio Tests)
weak_exo_LREERS <- alrtest(z = vecm_3_trace, A = A_LREERS, r = 1)
summary(weak_exo_LREERS)

weak_exo_RIRR <- alrtest(z = vecm_3_trace, A = A_RIRR, r = 1)
summary(weak_exo_RIRR)

weak_exo_LRGDPPCR <- alrtest(z = vecm_3_trace, A = A_LRGDPPCR, r = 1)
summary(weak_exo_LRGDPPCR)

weak_exo_OPENY <- alrtest(z = vecm_3_trace, A = A_OPENY, r = 1)
summary(weak_exo_OPENY)

weak_exo_FBYA <- alrtest(z = vecm_3_trace, A = A_FBYA, r = 1)
summary(weak_exo_FBYA)

weak_exo_NFAOFPY <- alrtest(z = vecm_3_trace, A = A_NFAOFPY, r = 1)
summary(weak_exo_NFAOFPY)

weak_exo_LPR2COMM5 <- alrtest(z = vecm_3_trace, A = A_LPR2COMM5, r = 1)
summary(weak_exo_LPR2COMM5)

# FBYA seems to be the only variable that is not weakly exogenous...

```

#   Extensions
##   Prepare Data

```{r results='hide', warning=FALSE}
# This part was quite messy - a combination of adjustment in R and manual adjustment in Excel was done to get the data ready
# Import data
# REERS <- read_excel("/Users/janhendrikpretorius/Library/CloudStorage/OneDrive-StellenboschUniversity/Masters-2023/Modules/Econometrics/Time-Series/Research Assignment/Working data/RAW/REERS.xlsx")
# RIRR <- read_excel("/Users/janhendrikpretorius/Library/CloudStorage/OneDrive-StellenboschUniversity/Masters-2023/Modules/Econometrics/Time-Series/Research Assignment/Working data/RAW/RIRR.xlsx")
# PRCOMM_IMF <- read_excel("/Users/janhendrikpretorius/Library/CloudStorage/OneDrive-StellenboschUniversity/Masters-2023/Modules/Econometrics/Time-Series/Research Assignment/Working data/RAW/PRCOMM_IMF.xlsx")
# 
# # Take the log of REERS
# REERS <- REERS %>%
#   mutate(LREERS = as.numeric(LREERS)) %>% 
#   mutate(LREERS = log(LREERS)) %>% 
#   filter(DATE < "2021-01-01" & DATE > "1980-01-01")
# 
# # Calculate real interest rates for SA and trading partners
# # Create a data frame with the weights
# weights <- data.frame(
#   Country = c("GER", "USA", "UK", "JPN", "CHI", "IND"),
#   Prior_1999 = c(0.47, 0.20, 0.20, 0.13, 0.00, 0.00),
#   Y1999 = c(0.45, 0.19, 0.19, 0.13, 0.04, 0.00),
#   Y2003 = c(0.45, 0.19, 0.19, 0.13, 0.04, 0.00),
#   Y2008 = c(0.41, 0.17, 0.13, 0.12, 0.15, 0.02),
#   Y2014 = c(0.37, 0.17, 0.07, 0.08, 0.26, 0.05),
#   Y2020 = c(0.39, 0.13, 0.05, 0.06, 0.31, 0.06)
# )
# 
# # Apply the appropriate weights based on the date ranges
# RIRR$Weight <- NA
# 
# RIRR$Weight[RIRR$DATE < as.Date("1999-01-01")] <- "Prior_1999"
# RIRR$Weight[RIRR$DATE >= as.Date("1999-01-01") & RIRR$DATE < as.Date("2003-01-01")] <- "Y1999"
# RIRR$Weight[RIRR$DATE >= as.Date("2003-01-01") & RIRR$DATE < as.Date("2008-01-01")] <- "Y2003"
# RIRR$Weight[RIRR$DATE >= as.Date("2008-01-01") & RIRR$DATE < as.Date("2014-01-01")] <- "Y2008"
# RIRR$Weight[RIRR$DATE >= as.Date("2014-01-01") & RIRR$DATE < as.Date("2020-01-01")] <- "Y2014"
# RIRR$Weight[RIRR$DATE >= as.Date("2020-01-01")] <- "Y2020"
# 
# 
# # Calculate the weighted average real interest rates for trading partners
# RIRR$Weighted_RIR_Trading_Partners <- NA
# 
# for (i in 1:nrow(RIRR)) {
#   weight_col <- RIRR$Weight[i]
#   weights_subset <- weights[, weight_col]
#   real_interest_rates_subset <- RIRR[i, c("RR_GER", "RR_US", "RR_UK", "RR_JPN", "RR_CHI", "RR_IND")]
#   RIRR$Weighted_RIR_Trading_Partners[i] <- sum(weights_subset * real_interest_rates_subset, na.rm = TRUE)
# }
# 
# # Subtract the weighted average real interest rates for trading partners from the South African real interest rate
# RIRR$RIRR <- RIRR$RR_SA - RIRR$Weighted_RIR_Trading_Partners
# RIRR <- RIRR  %>% 
#   filter(DATE < "2021-01-01" & DATE > "1980-01-01")
# 
# PRCOMM_IMF <- PRCOMM_IMF %>% 
#   filter(DATE < "2021-01-01" & DATE > "1980-01-01")
# 
# EXTENDED_DATA <- merged_df <- merge(REERS, RIRR, by = "DATE", all = TRUE)
# EXTENDED_DATA <- dplyr::select(EXTENDED_DATA, DATE, LREERS, RIRR)
# 
# EXTENDED_DATA <- merged_df <- merge(EXTENDED_DATA, PRCOMM_IMF, by = "DATE", all = TRUE)
# 
# # Prepare GDP data
# df <- read_excel("//Users/janhendrikpretorius/Library/CloudStorage/OneDrive-StellenboschUniversity/Masters-2023/Modules/Econometrics/Time-Series/Research Assignment/Working data/RAW/GDP.xlsx", sheet = 2)
# df$DATE <- as.Date(df$DATE)
# 
# # Assuming your dataframe is named df
# # Let's first normalize GDP per capita to 1 in 2000 for each country
# # Get the values in 2000-01-01 for each country
# norm_year <- "2009-01-01"
# norm_values <- df %>% 
#   dplyr::filter(DATE == norm_year) %>% 
#   dplyr::select(starts_with("RGDPPC_"))
# 
# # Normalize GDP per capita to 1 in 2000-01-01 for each country
# df <- df %>%
#   mutate(across(starts_with("RGDPPC_"), 
#                 ~ . / norm_values[[paste0("RGDPPC_", stringr::str_remove(cur_column(), "RGDPPC_"))]], 
#                 .names = "n_{.col}"))
# 
# 
# # Calculate the logarithm
# df <- df %>%
#   mutate(across(starts_with("n_RGDPPC_"), log, .names = "LRGDPPC_{.col}"))
# 
# # Calculate the weighted average for four trading partners.
# # Assuming the weights are in columns named as the country codes.
# # Let's say the trading partners are GER, USA, UK, and IND.
# df <- df %>%
#   mutate(LRGDPPCR_foreign = (LRGDPPC_n_RGDPPC_GER * GER + 
#                              LRGDPPC_n_RGDPPC_US * USA + 
#                              LRGDPPC_n_RGDPPC_UK * UK + 
#                              LRGDPPC_n_RGDPPC_IND * IND +
#                              LRGDPPC_n_RGDPPC_CHI * CHI +
#                              LRGDPPC_n_RGDPPC_JPN * JPN))
# 
# # Calculate the Real GDP per capita of South Africa, relative to trading partners.
# df <- df %>%
#   mutate(LRGDPPCR = LRGDPPC_n_RGDPPC_SA - LRGDPPCR_foreign)
# 
# write_xlsx(df, "/Users/janhendrikpretorius/Library/CloudStorage/OneDrive-StellenboschUniversity/Masters-2023/Modules/Econometrics/Time-Series/Research Assignment/Working data/RAW/LRGDPPC.xlsx")
# 
# # Manually adjust data and load in
# LRGDPPCR <- read_xlsx("/Users/janhendrikpretorius/Library/CloudStorage/OneDrive-StellenboschUniversity/Masters-2023/Modules/Econometrics/Time-Series/Research Assignment/Working data/RAW/LRGDPPC.xlsx")
# EXTENDED_DATA <- merged_df <- merge(REERS, RIRR, by = "DATE", all = TRUE)
# 
# # Transform OPENY
# OPENY <- read_excel("/Users/janhendrikpretorius/Library/CloudStorage/OneDrive-StellenboschUniversity/Masters-2023/Modules/Econometrics/Time-Series/Research Assignment/Working data/RAW/OPENY.xlsx")
# OPENY <- OPENY %>%
#   mutate(OPENY = ((EX + IM) / GDP)*100000000)
# 
# # Transform FBYA
# FISCAL <- read_excel("/Users/janhendrikpretorius/Library/CloudStorage/OneDrive-StellenboschUniversity/Masters-2023/Modules/Econometrics/Time-Series/Research Assignment/Working data/RAW/FISCAL.xlsx")
# # convert DATE to a date format
# FISCAL$DATE <- as.Date(FISCAL$DATE)
# # convert to a zoo object with a yearmon index
# FISCAL_zoo <- read.zoo(FISCAL, FUN = as.yearmon)
# 
# # aggregate to quarterly using the sum function
# FISCAL_qtr <- aggregate(FISCAL_zoo, as.yearqtr, sum)
# 
# # convert back to a data frame
# FISCAL <- as.data.frame(FISCAL_qtr)
# 
# 
# EXTENDED_DATA <- read_excel("/Users/janhendrikpretorius/Library/CloudStorage/OneDrive-StellenboschUniversity/Masters-2023/Modules/Econometrics/Time-Series/Research Assignment/Working data/RAW/EXTENDED_DATA.xlsx")
# # Convert the DATE column to a Date format if it is not already
# EXTENDED_DATA$DATE <- as.Date(EXTENDED_DATA$DATE)
# EXTENDED_DATA$PR2COMM <- as.numeric(EXTENDED_DATA$PR2COMM)
# 
# # Convert the dataframe to a zoo object with a yearmon index
# EXTENDED_DATA_zoo <- read.zoo(EXTENDED_DATA, FUN = as.yearmon)
# 
# # Aggregate to quarterly data. Here, I'm using the mean function. You might want to replace it with the appropriate function based on your data.
# EXTENDED_DATA_qtr <- aggregate(EXTENDED_DATA_zoo, as.yearqtr, mean)
# 
# # Convert back to a dataframe
# EXTENDED_DATA_qtr_df <- as.data.frame(EXTENDED_DATA_qtr)
# 
# # NFAOFPY
# NFAOFPY <- read_excel("/Users/janhendrikpretorius/Library/CloudStorage/OneDrive-StellenboschUniversity/Masters-2023/Modules/Econometrics/Time-Series/Research Assignment/Working data/RAW/NFAOFPY.xlsx")
# # Convert the DATE column to a Date format if it is not already
# NFAOFPY$DATE <- as.Date(NFAOFPY$DATE)
# 
# # Convert the dataframe to a zoo object with a yearmon index
# NFAOFPY_zoo <- read.zoo(NFAOFPY, FUN = as.yearmon)
# 
# # Aggregate to quarterly data. Here, I'm using the mean function. You might want to replace it with the appropriate function based on your data.
# NFAOFPY_qtr <- aggregate(NFAOFPY_zoo, as.yearqtr, mean)
# 
# # Convert back to a dataframe
# NFAOFPY_qtr_df <- as.data.frame(NFAOFPY_qtr)

```

##    Estimate extended model

```{r results='hide', warning=FALSE}
EXTENDED <- read_excel("/Users/janhendrikpretorius/Library/CloudStorage/OneDrive-StellenboschUniversity/Masters-2023/Modules/Econometrics/Time-Series/Research Assignment/Working data/EXTENDED_FINAL.xlsx")

# Create a new dataframe with the relevant columns
df_ext <- EXTENDED[, c("LREERS", "RIRR", "LRGDPPCR","OPENY", "FBYA", "NFAOFPY", "LPRCOMM")]

# Determine number of cointegrating 
# Johansen test for extended data
vecm_ext_trace <- ca.jo(df_ext, type = "trace", ecdet = "const", K = 4)
vecm_ext_eigen <- ca.jo(df_ext, type = "eigen", ecdet = "const", K = 4)
summary(vecm_ext_trace)
summary(vecm_ext_eigen)

vecm_ext <- VECM(df_ext, r =1, include = "const", estim = "ML", lag = 4) 
summary(vecm_ext)
```

##    Robustness checks

```{r results='hide', warning=FALSE}
# For the extended data we use vecm_ext_trace/eigen
# We must also estimate the underlying VAR to run some tests
var_ext <- VAR(df_ext, p = 4, type = "const")

# Exclusion tests: Wald Test
wald_result <- causality(var_ext, cause = "NFAOFPY")
print(wald_result)

# Serial correlation
var_ext <- vec2var(vecm_ext_trace, r = 1)
serial_ext <-  serial.test(var_1, lags.pt = 5, type = "PT.asymptotic")
serial_ext

# ARCH Effects
arch_ext <- arch.test(var_ext, lags.multi = 15, multivariate.only = TRUE)
arch_ext

# Normality of Residuals
norm_ext <- normality.test(var_ext, multivariate.only = TRUE)
norm_ext

# Impulse response functions
irf_ext <- irf(var_ext, impulse = "LRGDPPCR", response = "LREERS", n.ahead = 20)
plot(irf_ext)

# A matrices already defined earlier
# Perform the weak exogeneity test
weak_exo_LREERS <- alrtest(z = vecm_ext_trace, A = A_LREERS, r = 1)
summary(weak_exo_LREERS)

weak_exo_RIRR <- alrtest(z = vecm_ext_trace, A = A_RIRR, r = 1)
summary(weak_exo_RIRR)

weak_exo_LRGDPPCR <- alrtest(z = vecm_ext_trace, A = A_LRGDPPCR, r = 1)
summary(weak_exo_LRGDPPCR)

weak_exo_OPENY <- alrtest(z = vecm_ext_trace, A = A_OPENY, r = 1)
summary(weak_exo_OPENY)

weak_exo_FBYA <- alrtest(z = vecm_ext_trace, A = A_FBYA, r = 1)
summary(weak_exo_FBYA)

weak_exo_NFAOFPY <- alrtest(z = vecm_ext_trace, A = A_NFAOFPY, r = 1)
summary(weak_exo_NFAOFPY)

weak_exo_LPR2COMM5 <- alrtest(z = vecm_ext_trace, A = A_LPR2COMM5, r = 1)
summary(weak_exo_LPR2COMM5)
```


